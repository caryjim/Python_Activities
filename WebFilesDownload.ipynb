{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:52:34.774788Z",
     "iopub.status.busy": "2022-07-09T22:52:34.773789Z",
     "iopub.status.idle": "2022-07-09T22:52:35.610790Z",
     "shell.execute_reply": "2022-07-09T22:52:35.609796Z",
     "shell.execute_reply.started": "2022-07-09T22:52:34.773789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in d:\\program files\\python\\python38\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\program files\\python\\python38\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'D:\\Program Files\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:52:35.611789Z",
     "iopub.status.busy": "2022-07-09T22:52:35.610790Z",
     "iopub.status.idle": "2022-07-09T22:52:35.722799Z",
     "shell.execute_reply": "2022-07-09T22:52:35.721797Z",
     "shell.execute_reply.started": "2022-07-09T22:52:35.611789Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code from https://stackoverflow.com/a/54618327\n",
    "# By User https://stackoverflow.com/users/9189799/sim\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:52:35.723799Z",
     "iopub.status.busy": "2022-07-09T22:52:35.722799Z",
     "iopub.status.idle": "2022-07-09T22:52:35.738897Z",
     "shell.execute_reply": "2022-07-09T22:52:35.737907Z",
     "shell.execute_reply.started": "2022-07-09T22:52:35.723799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Crawling data from EDWeek on School Closures among K-12 \n",
    "# Webpage link: https://www.edweek.org/leadership/map-coronavirus-and-school-closures-in-2019-2020/2020/03\n",
    "# This link is obtained after completing a form with user information, masked with ... \n",
    "url = \".../data-coronavirus-and-school-closures-in-2019-2020/2021/12\"\n",
    "\n",
    "#If there is no such folder, the script will create one automatically\n",
    "folder_location = r'C:\\Users\\Desktop\\Edweek datasets on school closures'\n",
    "if not os.path.exists(folder_location):os.mkdir(folder_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:52:35.738897Z",
     "iopub.status.busy": "2022-07-09T22:52:35.738897Z",
     "iopub.status.idle": "2022-07-09T22:52:36.048738Z",
     "shell.execute_reply": "2022-07-09T22:52:36.048738Z",
     "shell.execute_reply.started": "2022-07-09T22:52:35.738897Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup= BeautifulSoup(response.text, \"html.parser\") \n",
    "# crawl files with .csv format\n",
    "for link in soup.select(\"a[href$='.csv']\"):\n",
    "    #Name the files using the last portion of each link which are unique in this case\n",
    "    filename = os.path.join(folder_location,link['href'].split('/')[-1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(urljoin(url,link['href'])).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:52:36.049732Z",
     "iopub.status.busy": "2022-07-09T22:52:36.049732Z",
     "iopub.status.idle": "2022-07-09T22:52:41.378273Z",
     "shell.execute_reply": "2022-07-09T22:52:41.378273Z",
     "shell.execute_reply.started": "2022-07-09T22:52:36.049732Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# crawl files with .xlsx format which is excel files\n",
    "for link in soup.select(\"a[href$='.xlsx']\"):\n",
    "    filename = os.path.join(folder_location,link['href'].split('/')[-1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(urljoin(url,link['href'])).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
